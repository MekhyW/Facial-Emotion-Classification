{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58899e2",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8ec1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.face_mesh_connections import FACEMESH_TESSELATION\n",
    "import json\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.sparse\n",
    "import pathlib, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a72dba",
   "metadata": {},
   "source": [
    "Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1, \n",
    "    refine_landmarks=False,  # Set to False to get 468 landmarks without iris\n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    \"\"\"\n",
    "    Process frame and extract facial landmarks\n",
    "    Returns None if no face is detected\n",
    "    \"\"\"\n",
    "    H, W, _ = frame.shape\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_mesh = face_mesh.process(rgb_image)\n",
    "    \n",
    "    # Check if face landmarks were detected\n",
    "    if not results_mesh.multi_face_landmarks:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Extract mesh points\n",
    "    mesh_points = np.array([\n",
    "        np.multiply([p.x, p.y], [W, H]).astype(int) \n",
    "        for p in results_mesh.multi_face_landmarks[0].landmark\n",
    "    ])\n",
    "    \n",
    "    # Calculate scale factor using nose tip and forehead\n",
    "    nose_tip = mesh_points[4]\n",
    "    forehead = mesh_points[151]\n",
    "    scale_factor = np.linalg.norm(forehead - nose_tip)\n",
    "    \n",
    "    if np.isclose(scale_factor, 0):\n",
    "        scale_factor = 1e-6\n",
    "        \n",
    "    return results_mesh, mesh_points, scale_factor\n",
    "\n",
    "def gera_grafos(results_mesh, mesh_points, scale_factor):\n",
    "    \"\"\"Generate graph from mesh points\"\"\"\n",
    "    graph = nx.Graph()\n",
    "    \n",
    "    # Add all nodes from mesh_points to the graph\n",
    "    for i in range(len(mesh_points)):\n",
    "        graph.add_node(i, pos=mesh_points[i])\n",
    "    \n",
    "    # Add edges based on MediaPipe face mesh connections\n",
    "    for connection in FACEMESH_TESSELATION:\n",
    "        graph.add_edge(connection[0], connection[1])\n",
    "    \n",
    "    return graph\n",
    "\n",
    "def plot_graph(graph, mesh_points):\n",
    "    \"\"\"Plot the facial mesh graph\"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    pos_dict = {i: mesh_points[i] for i in range(len(mesh_points))}\n",
    "    nx.draw_networkx(\n",
    "        graph, \n",
    "        pos=pos_dict, \n",
    "        node_size=10, \n",
    "        node_color='black', \n",
    "        edge_color='gray', \n",
    "        with_labels=False,\n",
    "        width=0.5\n",
    "    )\n",
    "    # Flip the image upside down to match face orientation\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(\"Facial Mesh Graph\")\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "def get_matrix_adj(graph):\n",
    "    \"\"\"Get adjacency matrix from graph\"\"\"\n",
    "    matrix_adj = nx.adjacency_matrix(graph)\n",
    "    sparse_matrix = scipy.sparse.csr_matrix(matrix_adj)\n",
    "    return sparse_matrix\n",
    "\n",
    "def save_adjacency_matrix(adjacency_matrix, filename):\n",
    "    \"\"\"Save adjacency matrix to file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_adj')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.npz')\n",
    "    scipy.sparse.save_npz(file_out, adjacency_matrix)\n",
    "\n",
    "def save_meshpoints(mesh_points, filename):\n",
    "    \"\"\"Save mesh points to JSON file\"\"\"\n",
    "    path_name = pathlib.Path(filename).parent.absolute()\n",
    "    emotion = path_name.name.split('_')[1]\n",
    "    path_name = path_name.parent.absolute()\n",
    "    path_name = path_name.joinpath(f'{emotion}_meshpoints')\n",
    "    \n",
    "    filename = pathlib.Path(filename).absolute()\n",
    "    path_name.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    file_out = path_name.joinpath(f'{filename.stem}.json')\n",
    "    with open(file_out, 'w') as outfile:\n",
    "        json.dump(mesh_points.tolist(), outfile)\n",
    "\n",
    "def pipeline(img_path, plot=False, verbose=False):\n",
    "    \"\"\"Main processing pipeline\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        frame = cv2.imread(img_path)\n",
    "        if frame is None:\n",
    "            if verbose:\n",
    "                print(f\"Could not read image: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Preprocess frame\n",
    "        results_mesh, mesh_points, scale_factor = preprocess_frame(frame)\n",
    "        \n",
    "        if results_mesh is None:\n",
    "            if verbose:\n",
    "                print(f\"No face detected in: {img_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Generate graph\n",
    "        graph = gera_grafos(results_mesh, mesh_points, scale_factor)\n",
    "        \n",
    "        # Save data\n",
    "        name = pathlib.Path(img_path).stem\n",
    "        adjacency_matrix = get_matrix_adj(graph)\n",
    "        save_adjacency_matrix(adjacency_matrix, img_path)\n",
    "        save_meshpoints(mesh_points, img_path)\n",
    "        \n",
    "        # Plot if requested\n",
    "        if plot:\n",
    "            plot_graph(graph, mesh_points)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def process_dataset(verbose=False, show_progress=True):\n",
    "    \"\"\"Process the entire dataset - ALL images in ALL emotion folders\"\"\"\n",
    "    print(\"Current path:\", pathlib.Path().absolute())\n",
    "    current_path = pathlib.Path().absolute()\n",
    "    parent_path = current_path.parent\n",
    "    \n",
    "    # Define emotion paths\n",
    "    emotion_folders = [\n",
    "        'face_angry', 'face_disgusted', 'face_happy', \n",
    "        'face_neutral', 'face_sad', 'face_surprised'\n",
    "    ]\n",
    "    \n",
    "    path_list = [parent_path / folder for folder in emotion_folders]\n",
    "    \n",
    "    total_processed = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for emotion_path in path_list:\n",
    "        if not emotion_path.exists():\n",
    "            print(f\"Path does not exist: {emotion_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nProcessing emotion: {emotion_path.name}\")\n",
    "        \n",
    "        error_count = 0\n",
    "        img_count = 0\n",
    "        \n",
    "        try:\n",
    "            emotion_files = os.listdir(emotion_path)\n",
    "            image_files = [f for f in emotion_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "            \n",
    "            print(f\"Found {len(image_files)} image files\")\n",
    "            \n",
    "            for img in image_files:\n",
    "                try:\n",
    "                    path_img = emotion_path / img\n",
    "                    \n",
    "                    # Show progress every 100 images (or based on show_progress)\n",
    "                    if show_progress and (img_count % 100 == 0 or img_count < 10):\n",
    "                        print(f\"Processing {img_count+1}/{len(image_files)}: {img}\")\n",
    "                    \n",
    "                    success = pipeline(str(path_img), plot=False, verbose=verbose)\n",
    "                    \n",
    "                    if success:\n",
    "                        total_processed += 1\n",
    "                        if verbose and img_count < 5:  # Only show first few if verbose\n",
    "                            print(f\"✅ Successfully processed: {img}\")\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        total_errors += 1\n",
    "                        if verbose:\n",
    "                            print(f\"❌ Failed to process: {img}\")\n",
    "                    \n",
    "                    img_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"❌ Error processing {img}: {str(e)}\")\n",
    "                    error_count += 1\n",
    "                    total_errors += 1\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Completed {emotion_path.name}: {img_count} total, {error_count} errors\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing folder {emotion_path}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "    print(f\"Total images processed successfully: {total_processed}\")\n",
    "    print(f\"Total errors: {total_errors}\")\n",
    "    if (total_processed + total_errors) > 0:\n",
    "        print(f\"Success rate: {total_processed/(total_processed + total_errors)*100:.1f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d1224",
   "metadata": {},
   "source": [
    "Run Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834d8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: c:\\Users\\Dell\\Downloads\\New folder\\Facial-Emotion-Classification\\GNN_updated\n",
      "\n",
      "Processing emotion: face_angry\n",
      "Found 0 image files\n",
      "Completed face_angry: 0 total, 0 errors\n",
      "\n",
      "Processing emotion: face_disgusted\n",
      "Found 0 image files\n",
      "Completed face_disgusted: 0 total, 0 errors\n",
      "\n",
      "Processing emotion: face_happy\n",
      "Found 0 image files\n",
      "Completed face_happy: 0 total, 0 errors\n",
      "\n",
      "Processing emotion: face_neutral\n",
      "Found 0 image files\n",
      "Completed face_neutral: 0 total, 0 errors\n",
      "\n",
      "Processing emotion: face_sad\n",
      "Found 0 image files\n",
      "Completed face_sad: 0 total, 0 errors\n",
      "\n",
      "Processing emotion: face_surprised\n",
      "Found 0 image files\n",
      "Completed face_surprised: 0 total, 0 errors\n",
      "\n",
      "=== FINAL SUMMARY ===\n",
      "Total images processed successfully: 0\n",
      "Total errors: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    process_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

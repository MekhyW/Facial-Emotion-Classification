{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8391 8996 10004 7980 7988 7999\n"
     ]
    }
   ],
   "source": [
    "images_sad = os.listdir('../face_sad')\n",
    "images_happy = os.listdir('../face_happy')\n",
    "images_neutral = os.listdir('../face_neutral')\n",
    "images_angry = os.listdir('../face_angry')\n",
    "images_surprised = os.listdir('../face_surprised')\n",
    "images_disgusted = os.listdir('../face_disgusted')\n",
    "\n",
    "print(len(images_sad), len(images_happy), len(images_neutral), len(images_angry), len(images_surprised), len(images_disgusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image):\n",
    "    detection_result = detector.detect(image)\n",
    "    if detection_result is None or not len(detection_result.face_blendshapes):\n",
    "        return None\n",
    "    blendshapes = detection_result.face_blendshapes[0]\n",
    "    return blendshapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_if_too_small(photo):\n",
    "    if photo.shape[0] < 300 and photo.shape[1] < 300:\n",
    "        photo = cv2.resize(photo, (300, 300), interpolation = cv2.INTER_CUBIC)\n",
    "    return photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 [2.7253367989032995e-06, 0.1256556361913681, 0.10741706192493439, 0.0001509089197497815, 0.05803176015615463, 0.029591243714094162, 3.763048516702838e-05, 2.0550118051687605e-07, 2.673679659892514e-07, 0.06272823363542557, 0.032636839896440506, 0.0249343104660511, 0.025372106581926346, 0.05538523569703102, 0.04630373418331146, 0.07394025474786758, 0.0958392322063446, 0.2888622581958771, 0.2607914209365845, 0.49653369188308716, 0.27751195430755615, 0.010500243864953518, 0.011249944567680359, 9.395218512509018e-05, 0.00032682070741429925, 0.0007976046181283891, 1.848598003562074e-05, 0.0001070261569111608, 0.01620500721037388, 0.008322201669216156, 0.0004258823173586279, 0.0005020815879106522, 0.00029130952316336334, 0.0002818749053403735, 0.0001998030347749591, 0.00023617588158231229, 0.13394880294799805, 0.09576203674077988, 0.0022862537298351526, 0.0039457776583731174, 0.004106540232896805, 0.005921841599047184, 0.029016654938459396, 0.008284938521683216, 0.648847758769989, 0.5493622422218323, 0.007123016286641359, 0.0250605046749115, 0.0004916937323287129, 0.0004932833253405988, 1.2277973837626632e-06, 1.6909757505345624e-06]\n"
     ]
    }
   ],
   "source": [
    "image = mp.Image.create_from_file('image.png')\n",
    "blendshapes = inference(image)\n",
    "scores = [cat.score for cat in blendshapes]\n",
    "print(len(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7050\n"
     ]
    }
   ],
   "source": [
    "blendshapes_surprised = []\n",
    "for image in images_surprised:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_surprised/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_surprised.append(scores)\n",
    "print(len(blendshapes_surprised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5190\n"
     ]
    }
   ],
   "source": [
    "blendshapes_disgusted = []\n",
    "for image in images_disgusted:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_disgusted/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_disgusted.append(scores)\n",
    "print(len(blendshapes_disgusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6764\n"
     ]
    }
   ],
   "source": [
    "blendshapes_angry = []\n",
    "for image in images_angry:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_angry/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_angry.append(scores)\n",
    "print(len(blendshapes_angry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8247\n"
     ]
    }
   ],
   "source": [
    "blendshapes_neutral = []\n",
    "for image in images_neutral:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_neutral/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_neutral.append(scores)\n",
    "print(len(blendshapes_neutral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8475\n"
     ]
    }
   ],
   "source": [
    "blendshapes_happy = []\n",
    "for image in images_happy:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_happy/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_happy.append(scores)\n",
    "print(len(blendshapes_happy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6708\n"
     ]
    }
   ],
   "source": [
    "blendshapes_sad = []\n",
    "for image in images_sad:\n",
    "    try:\n",
    "        cv2image = cv2.imread('../face_sad/' + image)\n",
    "        cv2image = resize_if_too_small(cv2image)\n",
    "        inferenceinput = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2image)\n",
    "    except (RuntimeError, AttributeError):\n",
    "        continue\n",
    "    blendshapes = inference(inferenceinput)\n",
    "    if blendshapes is not None:\n",
    "        scores = [cat.score for cat in blendshapes]\n",
    "        blendshapes_sad.append(scores)\n",
    "print(len(blendshapes_sad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sad = pd.DataFrame(blendshapes_sad)\n",
    "df_happy = pd.DataFrame(blendshapes_happy)\n",
    "df_neutral = pd.DataFrame(blendshapes_neutral)\n",
    "df_angry = pd.DataFrame(blendshapes_angry)\n",
    "df_surprise = pd.DataFrame(blendshapes_surprised)\n",
    "df_disgust = pd.DataFrame(blendshapes_disgusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sad['label'] = 'sad'\n",
    "df_happy['label'] = 'happy'\n",
    "df_neutral['label'] = 'neutral'\n",
    "df_angry['label'] = 'angry'\n",
    "df_surprise['label'] = 'surprise'\n",
    "df_disgust['label'] = 'disgust'\n",
    "\n",
    "df = pd.concat([df_sad, df_happy, df_neutral, df_angry, df_surprise, df_disgust])\n",
    "df.to_csv('blendshapes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
